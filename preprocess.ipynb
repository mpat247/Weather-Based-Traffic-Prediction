{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prerocessing Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\manav\\AppData\\Local\\Temp\\ipykernel_5196\\744342365.py:8: DtypeWarning: Columns (4,8,17,19,20,24,34) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_env = pd.read_csv(\"hourly_final.csv\")  # Env Canada Weather\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'datetime'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mE:\\manav\\Documents\\Masters\\ES8922\\Weather_Based_Traffic_Prediction\\venv\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3805\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3804\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3805\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3806\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mindex.pyx:167\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mindex.pyx:196\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7081\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7089\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mKeyError\u001b[39m: 'datetime'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[24]\u001b[39m\u001b[32m, line 40\u001b[39m\n\u001b[32m     37\u001b[39m df_ksi, df_tmc, df_collisions, df_env, df_era5 = load_datasets()\n\u001b[32m     39\u001b[39m \u001b[38;5;66;03m# --- Filter dates to 2015-2020 ---\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m40\u001b[39m df_ksi = \u001b[43mto_datetime_filter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_ksi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdatetime\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     41\u001b[39m df_tmc = to_datetime_filter(df_tmc, \u001b[33m\"\u001b[39m\u001b[33mcount_date\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     42\u001b[39m df_collisions = to_datetime_filter(df_collisions, \u001b[33m\"\u001b[39m\u001b[33mOccurrenceDate\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[24]\u001b[39m\u001b[32m, line 13\u001b[39m, in \u001b[36mto_datetime_filter\u001b[39m\u001b[34m(df, col, start, end)\u001b[39m\n\u001b[32m     12\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mto_datetime_filter\u001b[39m(df, col, start=\u001b[33m\"\u001b[39m\u001b[33m2015-01-01\u001b[39m\u001b[33m\"\u001b[39m, end=\u001b[33m\"\u001b[39m\u001b[33m2020-12-31\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m     df[col] = pd.to_datetime(\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcol\u001b[49m\u001b[43m]\u001b[49m, errors=\u001b[33m'\u001b[39m\u001b[33mcoerce\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m     14\u001b[39m     df[col] = df[col].dt.tz_localize(\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m     15\u001b[39m     mask = (df[col] >= pd.Timestamp(start)) & (df[col] <= pd.Timestamp(end))\n",
      "\u001b[36mFile \u001b[39m\u001b[32mE:\\manav\\Documents\\Masters\\ES8922\\Weather_Based_Traffic_Prediction\\venv\\Lib\\site-packages\\pandas\\core\\frame.py:4102\u001b[39m, in \u001b[36mDataFrame.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   4100\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.columns.nlevels > \u001b[32m1\u001b[39m:\n\u001b[32m   4101\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._getitem_multilevel(key)\n\u001b[32m-> \u001b[39m\u001b[32m4102\u001b[39m indexer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4103\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[32m   4104\u001b[39m     indexer = [indexer]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mE:\\manav\\Documents\\Masters\\ES8922\\Weather_Based_Traffic_Prediction\\venv\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3807\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   3808\u001b[39m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc.Iterable)\n\u001b[32m   3809\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[32m   3810\u001b[39m     ):\n\u001b[32m   3811\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[32m-> \u001b[39m\u001b[32m3812\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n\u001b[32m   3813\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[32m   3814\u001b[39m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[32m   3815\u001b[39m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[32m   3816\u001b[39m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[32m   3817\u001b[39m     \u001b[38;5;28mself\u001b[39m._check_indexing_error(key)\n",
      "\u001b[31mKeyError\u001b[39m: 'datetime'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def load_datasets():\n",
    "    df_ksi = pd.read_csv(\"Motor Vehicle Collisions with KSI Data - 4326.csv\")\n",
    "    df_tmc = pd.read_csv(\"tmc_raw_data_2010_2019.csv\")\n",
    "    df_collisions = pd.read_csv(\"Traffic_Collisions_Toronto_data.csv\")\n",
    "    df_env = pd.read_csv(\"hourly_final.csv\")  # Env Canada Weather\n",
    "    df_era5 = pd.read_csv(\"ERA.csv\")           # ERA5 Weather Data\n",
    "    return df_ksi, df_tmc, df_collisions, df_env, df_era5\n",
    "\n",
    "def to_datetime_filter(df, col, start=\"2015-01-01\", end=\"2020-12-31\"):\n",
    "    df[col] = pd.to_datetime(df[col], errors='coerce')\n",
    "    df[col] = df[col].dt.tz_localize(None)\n",
    "    mask = (df[col] >= pd.Timestamp(start)) & (df[col] <= pd.Timestamp(end))\n",
    "    return df[mask].copy()\n",
    "\n",
    "def process_coordinates(df, lat_col='lat', lon_col='lon', precision=3):\n",
    "    df[lat_col] = pd.to_numeric(df[lat_col], errors='coerce')\n",
    "    df[lon_col] = pd.to_numeric(df[lon_col], errors='coerce')\n",
    "    df['lat_round'] = df[lat_col].round(precision)\n",
    "    df['lon_round'] = df[lon_col].round(precision)\n",
    "    return df\n",
    "\n",
    "def process_datetime_hour(df, datetime_col, new_col='datetime_hour'):\n",
    "    df[new_col] = pd.to_datetime(df[datetime_col], errors='coerce')\n",
    "    df[new_col] = df[new_col].dt.tz_localize(None)\n",
    "    df[new_col] = df[new_col].dt.floor('H')\n",
    "    return df\n",
    "\n",
    "def combine_date_time(df, date_col, time_col, new_col='datetime'):\n",
    "    df[new_col] = pd.to_datetime(df[date_col] + ' ' + df[time_col], errors='coerce')\n",
    "    df[new_col] = df[new_col].dt.tz_localize(None)\n",
    "    return df\n",
    "\n",
    "# --- Load datasets ---\n",
    "df_ksi, df_tmc, df_collisions, df_env, df_era5 = load_datasets()\n",
    "\n",
    "# --- Filter dates to 2015-2020 ---\n",
    "df_ksi = to_datetime_filter(df_ksi, \"datetime\")\n",
    "df_tmc = to_datetime_filter(df_tmc, \"count_date\")\n",
    "df_collisions = to_datetime_filter(df_collisions, \"OccurrenceDate\")\n",
    "df_env = to_datetime_filter(df_env, \"timestamp\")\n",
    "df_era5 = to_datetime_filter(df_era5, \"timestamp\")\n",
    "\n",
    "# --- Process coordinates ---\n",
    "df_ksi = process_coordinates(df_ksi, lat_col='lat', lon_col='lon')\n",
    "df_tmc = process_coordinates(df_tmc, lat_col='lat', lon_col='lon')\n",
    "df_collisions = process_coordinates(df_collisions, lat_col='lat', lon_col='lon')\n",
    "df_env = process_coordinates(df_env, lat_col='lat', lon_col='lon')\n",
    "df_era5 = process_coordinates(df_era5, lat_col='lat', lon_col='lon')\n",
    "\n",
    "# --- Create datetime_hour column for merging ---\n",
    "df_ksi = process_datetime_hour(df_ksi, \"datetime\", new_col=\"datetime_hour\")\n",
    "\n",
    "# For TMC, combine count_date with start_time to create a full datetime then round to hour.\n",
    "df_tmc = combine_date_time(df_tmc, \"count_date\", \"start_time\", new_col=\"datetime_full\")\n",
    "df_tmc = process_datetime_hour(df_tmc, \"datetime_full\", new_col=\"datetime_hour\")\n",
    "\n",
    "# For collisions, use OccurrenceDate.\n",
    "df_collisions = process_datetime_hour(df_collisions, \"OccurrenceDate\", new_col=\"datetime_hour\")\n",
    "\n",
    "df_env = process_datetime_hour(df_env, \"timestamp\", new_col=\"datetime_hour\")\n",
    "df_era5 = process_datetime_hour(df_era5, \"timestamp\", new_col=\"datetime_hour\")\n",
    "\n",
    "# --- Optional: Select columns to keep (customize as needed) ---\n",
    "df_ksi = df_ksi[['datetime_hour', 'lat_round', 'lon_round', 'NEIGHBOURHOOD_158', 'INJURY', 'ACCLASS']]\n",
    "df_tmc = df_tmc[['datetime_hour', 'lat_round', 'lon_round', 'location_name']]\n",
    "df_collisions = df_collisions[['datetime_hour', 'lat_round', 'lon_round', 'Neighbourhood', 'Fatalities']]\n",
    "df_env = df_env[['datetime_hour', 'lat_round', 'lon_round', 'temperature', 'total_precipitation']]  # adjust column names as needed\n",
    "df_era5 = df_era5[['datetime_hour', 'lat_round', 'lon_round', 'temperature_2m', 'total_precipitation', 'u_component_of_wind_10m', 'v_component_of_wind_10m']]\n",
    "\n",
    "# --- Merge datasets on datetime_hour, lat_round, lon_round ---\n",
    "# Start with TMC as base since it represents traffic counts/locations.\n",
    "final_df = pd.merge(df_tmc, df_era5, on=['datetime_hour', 'lat_round', 'lon_round'], how='left')\n",
    "final_df = pd.merge(final_df, df_env, on=['datetime_hour', 'lat_round', 'lon_round'], how='left')\n",
    "final_df = pd.merge(final_df, df_ksi, on=['datetime_hour', 'lat_round', 'lon_round'], how='left')\n",
    "final_df = pd.merge(final_df, df_collisions, on=['datetime_hour', 'lat_round', 'lon_round'], how='left')\n",
    "\n",
    "# --- Optional: Handle missing values ---\n",
    "final_df.dropna(subset=['datetime_hour', 'lat_round', 'lon_round'], inplace=True)\n",
    "final_df.fillna(method='ffill', inplace=True)\n",
    "\n",
    "# --- Final output ---\n",
    "print(\"Final merged dataframe:\")\n",
    "print(final_df.head())\n",
    "final_df.to_csv(\"final_merged_dataset.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Exploring KSI Dataset ===\n",
      "Shape: (5571, 21)\n",
      "\n",
      "--- df.info() ---\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 5571 entries, 11303 to 16873\n",
      "Data columns (total 21 columns):\n",
      " #   Column             Non-Null Count  Dtype         \n",
      "---  ------             --------------  -----         \n",
      " 0   DATE               5571 non-null   datetime64[ns]\n",
      " 1   TIME               5571 non-null   int64         \n",
      " 2   ACCLASS            5571 non-null   object        \n",
      " 3   INJURY             3141 non-null   object        \n",
      " 4   FATAL_NO           376 non-null    float64       \n",
      " 5   IMPACTYPE          5567 non-null   object        \n",
      " 6   ROAD_CLASS         5515 non-null   object        \n",
      " 7   ACCLOC             5533 non-null   object        \n",
      " 8   TRAFFCTL           5568 non-null   object        \n",
      " 9   VISIBILITY         5553 non-null   object        \n",
      " 10  LIGHT              5571 non-null   object        \n",
      " 11  RDSFCOND           5548 non-null   object        \n",
      " 12  VEHTYPE            3406 non-null   object        \n",
      " 13  INVTYPE            5564 non-null   object        \n",
      " 14  AUTOMOBILE         5086 non-null   object        \n",
      " 15  PEDESTRIAN         2358 non-null   object        \n",
      " 16  CYCLIST            607 non-null    object        \n",
      " 17  NEIGHBOURHOOD_158  5571 non-null   object        \n",
      " 18  lon                5571 non-null   float64       \n",
      " 19  lat                5571 non-null   float64       \n",
      " 20  datetime           5571 non-null   datetime64[ns]\n",
      "dtypes: datetime64[ns](2), float64(3), int64(1), object(15)\n",
      "memory usage: 957.5+ KB\n",
      "\n",
      "\n",
      "--- Null Counts ---\n",
      "DATE                    0\n",
      "TIME                    0\n",
      "ACCLASS                 0\n",
      "INJURY               2430\n",
      "FATAL_NO             5195\n",
      "IMPACTYPE               4\n",
      "ROAD_CLASS             56\n",
      "ACCLOC                 38\n",
      "TRAFFCTL                3\n",
      "VISIBILITY             18\n",
      "LIGHT                   0\n",
      "RDSFCOND               23\n",
      "VEHTYPE              2165\n",
      "INVTYPE                 7\n",
      "AUTOMOBILE            485\n",
      "PEDESTRIAN           3213\n",
      "CYCLIST              4964\n",
      "NEIGHBOURHOOD_158       0\n",
      "lon                     0\n",
      "lat                     0\n",
      "datetime                0\n",
      "\n",
      "--- KSI Dataset: 25 Random Unique Rows ---\n",
      "      DATE  TIME          ACCLASS  INJURY  FATAL_NO             IMPACTYPE      ROAD_CLASS                ACCLOC             TRAFFCTL VISIBILITY            LIGHT RDSFCOND                     VEHTYPE           INVTYPE AUTOMOBILE PEDESTRIAN CYCLIST            NEIGHBOURHOOD_158        lon       lat            datetime\n",
      "2019-06-09  1812 Non-Fatal Injury   Major       NaN             SMV Other Major Arterial       Non Intersection           No Control      Clear         Daylight      Dry   Automobile, Station Wagon            Driver        Yes        NaN     NaN            High Park-Swansea -79.474414 43.635577 2019-06-09 18:00:00\n",
      "2016-07-07   654 Non-Fatal Injury   Major       NaN              Rear End  Major Arterial       At Intersection       Traffic Signal      Clear         Daylight      Dry                  Motorcycle Motorcycle Driver        Yes        NaN     NaN       West Humber-Clairville -79.605426 43.739031 2016-07-07 07:00:00\n",
      "2016-02-23  2146 Non-Fatal Injury   Minor       NaN Pedestrian Collisions  Minor Arterial      Non Intersection           No Control      Clear Dark, artificial      Dry   Automobile, Station Wagon            Driver        Yes        Yes     NaN            Trinity-Bellwoods -79.422458 43.653796 2016-02-23 22:00:00\n",
      "2018-10-26  1157 Non-Fatal Injury     NaN       NaN             Sideswipe  Major Arterial       At Intersection       Traffic Signal      Clear         Daylight      Dry   Automobile, Station Wagon            Driver        Yes        NaN     NaN              North Riverdale -79.358829 43.676131 2018-10-26 12:00:00\n",
      "2016-04-10  1130 Non-Fatal Injury     NaN       NaN Pedestrian Collisions  Major Arterial      Non Intersection Streetcar (Stop for)      Clear         Daylight      Dry   Automobile, Station Wagon            Driver        Yes        Yes     NaN           Yonge-Bay Corridor -79.386615 43.650843 2016-04-10 12:00:00\n",
      "2016-08-21   634 Non-Fatal Injury   Major       NaN             SMV Other  Major Arterial  Intersection Related           No Control      Clear         Daylight      Dry   Automobile, Station Wagon            Driver        Yes        NaN     NaN           Don Valley Village -79.363033 43.790763 2016-08-21 07:00:00\n",
      "2018-01-02  1900 Non-Fatal Injury     NaN       NaN           Approaching  Major Arterial      Non Intersection           No Control      Clear Dark, artificial      Dry               Passenger Van            Driver        Yes        NaN     NaN           Don Valley Village -79.362178 43.790946 2018-01-02 19:00:00\n",
      "2016-04-06  1440 Non-Fatal Injury     NaN       NaN Pedestrian Collisions  Minor Arterial       At Intersection           No Control      Clear         Daylight      Dry Municipal Transit Bus (TTC)            Driver        NaN        Yes     NaN          Stonegate-Queensway -79.503116 43.627577 2016-04-06 15:00:00\n",
      "2016-09-20  1721 Non-Fatal Injury     NaN       NaN Pedestrian Collisions  Major Arterial       At Intersection Pedestrian Crossover      Clear         Daylight      Dry   Automobile, Station Wagon            Driver        Yes        Yes     NaN Runnymede-Bloor West Village -79.485935 43.652877 2016-09-20 17:00:00\n",
      "2016-07-10  2240 Non-Fatal Injury     NaN       NaN Pedestrian Collisions  Major Arterial       At Intersection       Traffic Signal      Clear Dark, artificial      Dry   Automobile, Station Wagon            Driver        Yes        Yes     NaN            Humber Bay Shores -79.481197 43.622859 2016-07-10 23:00:00\n",
      "2017-04-23  2044 Non-Fatal Injury     NaN       NaN      Turning Movement  Major Arterial       At Intersection   Traffic Controller      Clear             Dusk      Dry               Pick Up Truck            Driver        Yes        NaN     NaN                North Toronto -79.399272 43.711005 2017-04-23 21:00:00\n",
      "2018-12-04  1932            Fatal     NaN       NaN Pedestrian Collisions  Major Arterial      Non Intersection           No Control      Clear             Dark      Dry   Automobile, Station Wagon            Driver        Yes        Yes     NaN          Bendale-Glen Andrew -79.267612 43.758383 2018-12-04 20:00:00\n",
      "2016-10-27  1506 Non-Fatal Injury     NaN       NaN Pedestrian Collisions  Major Arterial      Non Intersection           No Control       Rain         Daylight      Wet   Automobile, Station Wagon            Driver        Yes        Yes     NaN      York University Heights -79.493770 43.781680 2016-10-27 15:00:00\n",
      "2016-08-05  1225            Fatal   Fatal      50.0 Pedestrian Collisions  Major Arterial      Non Intersection           No Control      Clear         Daylight      Dry                         NaN        Pedestrian        Yes        Yes     NaN              Willowdale West -79.422359 43.778243 2016-08-05 12:00:00\n",
      "2017-10-18   906            Fatal   Fatal      50.0    Cyclist Collisions  Major Arterial       At Intersection            Stop Sign      Clear         Daylight      Dry                     Bicycle           Cyclist        Yes        NaN     Yes               South Parkdale -79.431827 43.637950 2017-10-18 09:00:00\n",
      "2016-12-21   959 Non-Fatal Injury     NaN       NaN Pedestrian Collisions  Major Arterial       At Intersection       Traffic Signal      Clear         Daylight      Wet               Truck-Tractor      Truck Driver        NaN        Yes     NaN                    Downsview -79.481548 43.724372 2016-12-21 10:00:00\n",
      "2018-02-17  2319            Fatal   Fatal      10.0             SMV Other  Major Arterial      Non Intersection           No Control        NaN             Dark      NaN   Automobile, Station Wagon            Driver        Yes        NaN     NaN        Bayview Woods-Steeles -79.392772 43.788287 2018-02-17 23:00:00\n",
      "2015-06-07  1830 Non-Fatal Injury   Major       NaN    Cyclist Collisions  Major Arterial       At Intersection       Traffic Signal      Clear         Daylight      Dry                     Bicycle           Cyclist        NaN        NaN     Yes          Lawrence Park South -79.402156 43.725032 2015-06-07 18:00:00\n",
      "2019-12-13  2041 Non-Fatal Injury     NaN       NaN Pedestrian Collisions  Major Arterial       At Intersection       Traffic Signal      Clear Dark, artificial      Dry   Automobile, Station Wagon            Driver        Yes        Yes     NaN                    Downsview -79.486408 43.744704 2019-12-13 21:00:00\n",
      "2016-05-19  1200 Non-Fatal Injury   Minor       NaN      Turning Movement  Major Arterial       At Intersection       Traffic Signal      Clear         Daylight      Dry               Pick Up Truck            Driver        Yes        NaN     NaN                       Rustic -79.505931 43.710971 2016-05-19 12:00:00\n",
      "2017-06-13  2001 Non-Fatal Injury   Major       NaN             Sideswipe             NaN      Non Intersection           No Control      Clear         Daylight      Dry                  Motorcycle Motorcycle Driver        Yes        NaN     NaN            Banbury-Don Mills -79.330257 43.725211 2017-06-13 20:00:00\n",
      "2017-10-23   833 Non-Fatal Injury   Major       NaN Pedestrian Collisions  Major Arterial       At Intersection       Traffic Signal      Clear         Daylight      Dry                         NaN        Pedestrian        Yes        Yes     NaN             Wexford/Maryvale -79.310153 43.758959 2017-10-23 09:00:00\n",
      "2018-10-04  1630 Non-Fatal Injury     NaN       NaN Pedestrian Collisions  Major Arterial      Non Intersection           No Control      Clear         Daylight      Dry                Truck - Open      Truck Driver        NaN        Yes     NaN                Humber Summit -79.560573 43.767333 2018-10-04 16:00:00\n",
      "2017-04-05  1454 Non-Fatal Injury     NaN       NaN Pedestrian Collisions           Local At/Near Private Drive           No Control      Clear         Daylight      Dry   Automobile, Station Wagon            Driver        Yes        Yes     NaN     Humber Heights-Westmount -79.522189 43.688971 2017-04-05 15:00:00\n",
      "2019-09-17  2000            Fatal Minimal       NaN Pedestrian Collisions  Major Arterial  Intersection Related            Stop Sign      Clear         Daylight      Dry               Pick Up Truck            Driver        Yes        Yes     NaN             Wexford/Maryvale -79.291835 43.745886 2019-09-17 20:00:00\n",
      "\n",
      "=== Exploring TMC Dataset ===\n",
      "Shape: (122570, 6)\n",
      "\n",
      "--- df.info() ---\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 122570 entries, 99531 to 223816\n",
      "Data columns (total 6 columns):\n",
      " #   Column         Non-Null Count   Dtype         \n",
      "---  ------         --------------   -----         \n",
      " 0   count_date     122570 non-null  datetime64[ns]\n",
      " 1   start_time     122570 non-null  datetime64[ns]\n",
      " 2   end_time       122570 non-null  object        \n",
      " 3   lon            122570 non-null  float64       \n",
      " 4   lat            122570 non-null  float64       \n",
      " 5   location_name  122570 non-null  object        \n",
      "dtypes: datetime64[ns](2), float64(2), object(2)\n",
      "memory usage: 6.5+ MB\n",
      "\n",
      "\n",
      "--- Null Counts ---\n",
      "count_date       0\n",
      "start_time       0\n",
      "end_time         0\n",
      "lon              0\n",
      "lat              0\n",
      "location_name    0\n",
      "\n",
      "--- TMC Dataset: 25 Random Unique Rows ---\n",
      "count_date          start_time            end_time        lon       lat                                           location_name\n",
      "2015-09-16 2015-09-16 08:00:00 2015-09-16T07:45:00 -79.375874 43.798753                               Pineway Blvd / Cummer Ave\n",
      "2017-07-05 2017-07-05 08:00:00 2017-07-05T07:45:00 -79.392200 43.713786                        Mount Pleasant Rd / Keewatin Ave\n",
      "2017-01-17 2017-01-17 08:00:00 2017-01-17T07:45:00 -79.383585 43.688320                        Mount Pleasant Rd / Inglewood Dr\n",
      "2018-11-14 2018-11-14 08:00:00 2018-11-14T07:45:00 -79.394934 43.690181                                   Yonge St / Heath St W\n",
      "2018-03-21 2018-03-21 08:00:00 2018-03-21T07:45:00 -79.449648 43.641865                             Parkdale Rd / Sunnyside Ave\n",
      "2015-07-09 2015-07-09 08:00:00 2015-07-09T07:45:00 -79.363002 43.660087                              Dundas St E / Sackville St\n",
      "2016-07-20 2016-07-20 08:00:00 2016-07-20T07:45:00 -79.382783 43.670153                                   Church St / Hayden St\n",
      "2017-07-19 2017-07-19 08:00:00 2017-07-19T07:45:00 -79.421189 43.699427                              Glenayr Rd / Dewbourne Ave\n",
      "2015-11-12 2015-11-12 08:00:00 2015-11-12T07:45:00 -79.524995 43.596419                   Lake Shore Blvd W / Twenty Seventh St\n",
      "2017-12-12 2017-12-12 08:00:00 2017-12-12T07:45:00 -79.512485 43.647118                               Bloor St W / Cliveden Ave\n",
      "2017-09-07 2017-09-07 08:00:00 2017-09-07T07:45:00 -79.453397 43.707908                             Dufferin St / Glen Park Ave\n",
      "2018-06-28 2018-06-28 08:00:00 2018-06-28T07:45:00 -79.409229 43.677112                                Walmer Rd / Davenport Rd\n",
      "2019-06-13 2019-06-13 08:00:00 2019-06-13T07:45:00 -79.404968 43.789742       Cummer Ave: Becky Cheung Crt - Willow Heights Crt\n",
      "2015-06-15 2015-06-15 08:00:00 2015-06-15T07:45:00 -79.284073 43.693941                               Denton Ave / Pharmacy Ave\n",
      "2016-04-04 2016-04-04 08:00:00 2016-04-04T07:45:00 -79.417824 43.788978                                 Yonge St / Wedgewood Dr\n",
      "2019-02-20 2019-02-20 08:00:00 2019-02-20T07:45:00 -79.309707 43.730014                                Sloane Ave / Elvaston Dr\n",
      "2018-02-08 2018-02-08 08:00:00 2018-02-08T07:45:00 -79.393036 43.716031                      Mount Pleasant Rd / Sheldrake Blvd\n",
      "2016-04-28 2016-04-28 08:00:00 2016-04-28T07:45:00 -79.428614 43.642218                                Queen St W / Dufferin St\n",
      "2016-12-15 2016-12-15 08:00:00 2016-12-15T07:45:00 -79.257147 43.758958                                 Brimley Rd / Dorcot Ave\n",
      "2015-09-15 2015-09-15 08:00:00 2015-09-15T07:45:00 -79.389531 43.727791 Lawrence Ave E / Wanless Cres / Ww E Wanless N Lawrence\n",
      "2016-06-27 2016-06-27 08:00:00 2016-06-27T07:45:00 -79.488137 43.647728                               Bloor St W / Riverside Dr\n",
      "2018-04-03 2018-04-03 08:00:00 2018-04-03T07:45:00 -79.505567 43.709245                     Jane St / Maple Leaf Dr / Church St\n",
      "2016-01-04 2016-01-04 08:00:00 2016-01-04T07:45:00 -79.327686 43.760666                              York Mills Rd / Fenside Dr\n",
      "2016-11-08 2016-11-08 08:00:00 2016-11-08T07:45:00 -79.384759 43.672176                                     Church St / Park Rd\n",
      "2016-05-03 2016-05-03 08:00:00 2016-05-03T07:45:00 -79.577138 43.705247                             Martin Grove Rd / Vulcan St\n",
      "\n",
      "=== Exploring Collisions Dataset ===\n",
      "Shape: (417795, 8)\n",
      "\n",
      "--- df.info() ---\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 417795 entries, 9000 to 499537\n",
      "Data columns (total 8 columns):\n",
      " #   Column             Non-Null Count   Dtype         \n",
      "---  ------             --------------   -----         \n",
      " 0   OccurrenceDate     417795 non-null  datetime64[ns]\n",
      " 1   Hour               417795 non-null  int64         \n",
      " 2   lon                417795 non-null  float64       \n",
      " 3   lat                417795 non-null  float64       \n",
      " 4   Neighbourhood      417795 non-null  object        \n",
      " 5   Fatalities         417795 non-null  int64         \n",
      " 6   Injury_Collisions  417795 non-null  object        \n",
      " 7   PD_Collisions      417795 non-null  object        \n",
      "dtypes: datetime64[ns](1), float64(2), int64(2), object(3)\n",
      "memory usage: 28.7+ MB\n",
      "\n",
      "\n",
      "--- Null Counts ---\n",
      "OccurrenceDate       0\n",
      "Hour                 0\n",
      "lon                  0\n",
      "lat                  0\n",
      "Neighbourhood        0\n",
      "Fatalities           0\n",
      "Injury_Collisions    0\n",
      "PD_Collisions        0\n",
      "\n",
      "--- Collisions Dataset: 25 Random Unique Rows ---\n",
      "     OccurrenceDate  Hour        lon       lat                            Neighbourhood  Fatalities Injury_Collisions PD_Collisions\n",
      "2017-10-15 04:00:00    10 -79.487302 43.733588                Downsview-Roding-CFB (26)           0                NO           YES\n",
      "2020-02-13 05:00:00    13 -79.320056 43.799489                          LAmoreaux (117)           0                NO            NO\n",
      "2015-08-31 04:00:00    17 -79.634896 43.747439               West Humber-Clairville (1)           0               YES            NO\n",
      "2018-06-02 04:00:00    15 -79.194539 43.764873                          West Hill (136)           0                NO           YES\n",
      "2015-03-09 04:00:00    19 -79.356810 43.807030                   Hillcrest Village (48)           0               YES            NO\n",
      "2019-11-24 05:00:00    22 -79.580363 43.741743         Thistletown-Beaumond Heights (3)           0                NO            NO\n",
      "2018-07-04 04:00:00    16 -79.396341 43.723959                Lawrence Park South (103)           0                NO           YES\n",
      "2017-01-02 05:00:00    17 -79.409185 43.644676                             Niagara (82)           0                NO            NO\n",
      "2016-09-24 04:00:00    12 -79.413760 43.653422                   Trinity-Bellwoods (81)           0                NO            NO\n",
      "2017-07-22 04:00:00    14 -79.456588 43.683108                 Caledonia-Fairbank (109)           0                NO           YES\n",
      "2015-11-05 05:00:00     8 -79.548476 43.669889                  Princess-Rosethorn (10)           0               YES            NO\n",
      "2017-06-22 04:00:00    14 -79.493278 43.610738 Mimico (includes Humber Bay Shores) (17)           0                NO           YES\n",
      "2016-11-07 05:00:00    19 -79.452385 43.665497 Dovercourt-Wallace Emerson-Junction (93)           0               YES            NO\n",
      "2020-02-08 05:00:00    18 -79.337039 43.798128                       Pleasant View (46)           0                NO            NO\n",
      "2016-12-15 05:00:00    14 -79.326746 43.813126                            Steeles (116)           0                NO           YES\n",
      "2015-12-05 05:00:00    10 -79.394170 43.745935   Bridle Path-Sunnybrook-York Mills (41)           0                NO           YES\n",
      "2015-08-29 04:00:00    15 -79.407209 43.711169                     Yonge-Eglinton (100)           0                NO           YES\n",
      "2016-05-21 04:00:00    14 -79.379024 43.706246                 Mount Pleasant East (99)           0                NO           YES\n",
      "2017-05-23 04:00:00    14 -79.406685 43.744150                St.Andrew-Windfields (40)           0                NO            NO\n",
      "2020-09-30 04:00:00    15 -79.417985 43.669273                               Annex (95)           0                NO           YES\n",
      "2015-05-01 04:00:00    10 -79.436326 43.725919                 Englemount-Lawrence (32)           0                NO           YES\n",
      "2017-01-24 05:00:00    16 -79.445699 43.664897 Dovercourt-Wallace Emerson-Junction (93)           0                NO           YES\n",
      "2015-10-29 04:00:00    16 -79.327524 43.726645                     Flemingdon Park (44)           0                NO           YES\n",
      "2015-11-02 05:00:00     7 -79.471476 43.690978            Beechborough-Greenbrook (112)           0                NO           YES\n",
      "2015-01-10 05:00:00     4 -79.328359 43.729355                   Banbury-Don Mills (42)           0                NO            NO\n",
      "\n",
      "=== Exploring Env Canada Dataset ===\n",
      "Shape: (52355, 10)\n",
      "\n",
      "--- df.info() ---\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 52355 entries, 36750 to 89104\n",
      "Data columns (total 10 columns):\n",
      " #   Column             Non-Null Count  Dtype         \n",
      "---  ------             --------------  -----         \n",
      " 0   LOCAL_DATE         52355 non-null  datetime64[ns]\n",
      " 1   LOCAL_HOUR         52355 non-null  int64         \n",
      " 2   TEMP               52345 non-null  float64       \n",
      " 3   WINDCHILL          0 non-null      float64       \n",
      " 4   PRECIP_AMOUNT      51802 non-null  float64       \n",
      " 5   RELATIVE_HUMIDITY  52347 non-null  float64       \n",
      " 6   VISIBILITY         0 non-null      float64       \n",
      " 7   WEATHER_ENG_DESC   0 non-null      float64       \n",
      " 8   lon                52355 non-null  float64       \n",
      " 9   lat                52355 non-null  float64       \n",
      "dtypes: datetime64[ns](1), float64(8), int64(1)\n",
      "memory usage: 4.4 MB\n",
      "\n",
      "\n",
      "--- Null Counts ---\n",
      "LOCAL_DATE               0\n",
      "LOCAL_HOUR               0\n",
      "TEMP                    10\n",
      "WINDCHILL            52355\n",
      "PRECIP_AMOUNT          553\n",
      "RELATIVE_HUMIDITY        8\n",
      "VISIBILITY           52355\n",
      "WEATHER_ENG_DESC     52355\n",
      "lon                      0\n",
      "lat                      0\n",
      "\n",
      "--- Env Canada Dataset: 1 Random Unique Rows ---\n",
      "LOCAL_DATE  LOCAL_HOUR  TEMP  WINDCHILL  PRECIP_AMOUNT  RELATIVE_HUMIDITY  VISIBILITY  WEATHER_ENG_DESC   lon       lat\n",
      "2020-12-31           0   3.2        NaN            0.0               63.0         NaN               NaN -79.4 43.666667\n",
      "\n",
      "=== Exploring ERA5 Dataset ===\n",
      "Shape: (525850, 8)\n",
      "\n",
      "--- df.info() ---\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 525850 entries, 0 to 526056\n",
      "Data columns (total 8 columns):\n",
      " #   Column                   Non-Null Count   Dtype         \n",
      "---  ------                   --------------   -----         \n",
      " 0   timestamp                525850 non-null  datetime64[ns]\n",
      " 1   temperature_2m           525850 non-null  float64       \n",
      " 2   dewpoint_temperature_2m  525850 non-null  float64       \n",
      " 3   total_precipitation      525850 non-null  float64       \n",
      " 4   u_component_of_wind_10m  525850 non-null  float64       \n",
      " 5   v_component_of_wind_10m  525850 non-null  float64       \n",
      " 6   lon                      525850 non-null  float64       \n",
      " 7   lat                      525850 non-null  float64       \n",
      "dtypes: datetime64[ns](1), float64(7)\n",
      "memory usage: 36.1 MB\n",
      "\n",
      "\n",
      "--- Null Counts ---\n",
      "timestamp                  0\n",
      "temperature_2m             0\n",
      "dewpoint_temperature_2m    0\n",
      "total_precipitation        0\n",
      "u_component_of_wind_10m    0\n",
      "v_component_of_wind_10m    0\n",
      "lon                        0\n",
      "lat                        0\n",
      "\n",
      "--- ERA5 Dataset: 10 Random Unique Rows ---\n",
      " timestamp  temperature_2m  dewpoint_temperature_2m  total_precipitation  u_component_of_wind_10m  v_component_of_wind_10m      lon     lat\n",
      "2015-01-01      267.469437               256.379730             0.000267                 7.538605                 3.411713 -79.3641 43.7326\n",
      "2015-01-01      267.221390               255.830902             0.000185                 6.333527                 3.142181 -79.5181 43.7731\n",
      "2015-01-01      268.500687               259.366058             0.000525                10.322784                 4.029877 -79.1845 43.7636\n",
      "2015-01-01      267.469437               256.379730             0.000267                 7.538605                 3.411713 -79.3832 43.6532\n",
      "2015-01-01      268.500687               259.366058             0.000525                10.322784                 4.029877 -79.2454 43.7078\n",
      "2015-01-01      268.500687               259.366058             0.000525                10.322784                 4.029877 -79.2263 43.7845\n",
      "2015-01-01      267.162796               256.330902             0.000333                 7.084503                 3.222260 -79.2939 43.7996\n",
      "2015-01-01      267.738968               257.090668             0.000398                 8.947784                 3.726166 -79.3017 43.6650\n",
      "2015-01-01      266.846390               255.664886             0.000197                 5.579620                 2.945892 -79.6205 43.5906\n",
      "2015-01-01      267.469437               256.379730             0.000267                 7.538605                 3.411713 -79.4309 43.6816\n"
     ]
    }
   ],
   "source": [
    "###############################################################################\n",
    "# CONTINUATION: Basic EDA/Exploration in Plain Text\n",
    "#\n",
    "# Use this immediately after your preprocessing code. Simply call:\n",
    "#   basic_exploration_console(df_ksi, df_tmc, df_collisions, df_env, df_era5)\n",
    "# to see shapes, df.info(), null counts, and a 25-row random sample.\n",
    "###############################################################################\n",
    "\n",
    "import io\n",
    "\n",
    "def explore_dataframe_console(df, df_name, unique_subset=None, sample_size=25):\n",
    "    \"\"\"\n",
    "    Prints plain-text EDA information to the console:\n",
    "      - shape\n",
    "      - df.info() (column types, non-null counts)\n",
    "      - null counts\n",
    "      - sample_size random unique rows\n",
    "    \"\"\"\n",
    "    print(f\"\\n=== Exploring {df_name} ===\")\n",
    "    print(\"Shape:\", df.shape)\n",
    "\n",
    "    # Capture df.info() output\n",
    "    print(\"\\n--- df.info() ---\")\n",
    "    info_buffer = io.StringIO()\n",
    "    df.info(buf=info_buffer)\n",
    "    info_str = info_buffer.getvalue()\n",
    "    print(info_str)\n",
    "\n",
    "    # Null counts\n",
    "    print(\"\\n--- Null Counts ---\")\n",
    "    null_series = df.isna().sum()\n",
    "    print(null_series.to_string())\n",
    "\n",
    "    # Display random unique rows\n",
    "    _df = df.drop_duplicates(subset=unique_subset) if unique_subset else df.drop_duplicates()\n",
    "    nrows = min(sample_size, len(_df))\n",
    "    if nrows > 0:\n",
    "        sample = _df.sample(nrows, random_state=42)\n",
    "        print(f\"\\n--- {df_name}: {nrows} Random Unique Rows ---\")\n",
    "        print(sample.to_string(index=False))\n",
    "    else:\n",
    "        print(f\"No rows found in {df_name} after dropping duplicates.\")\n",
    "\n",
    "\n",
    "def basic_exploration_console(df_ksi, df_tmc, df_collisions, df_env, df_era5):\n",
    "    \"\"\"\n",
    "    Runs explore_dataframe_console() on each final DataFrame,\n",
    "    printing the results to the console in a copyable plain-text format.\n",
    "    \"\"\"\n",
    "    explore_dataframe_console(df_ksi, \"KSI Dataset\", unique_subset=[\"lon\",\"lat\"], sample_size=25)\n",
    "    explore_dataframe_console(df_tmc, \"TMC Dataset\", unique_subset=[\"lon\",\"lat\"], sample_size=25)\n",
    "    explore_dataframe_console(df_collisions, \"Collisions Dataset\", unique_subset=[\"lon\",\"lat\"], sample_size=25)\n",
    "    explore_dataframe_console(df_env, \"Env Canada Dataset\", unique_subset=[\"lon\",\"lat\"], sample_size=25)\n",
    "    explore_dataframe_console(df_era5, \"ERA5 Dataset\", unique_subset=[\"lon\",\"lat\"], sample_size=25)\n",
    "\n",
    "\n",
    "# Usage Example:\n",
    "# After your main script finishes and you have df_ksi, df_tmc, df_collisions, df_env, df_era5:\n",
    "basic_exploration_console(df_ksi, df_tmc, df_collisions, df_env, df_era5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "KSI Dataset:\n",
      "--------------------------------------------------------------------------------\n",
      "Row 1:\n",
      "  _id: 1\n",
      "  accnum: 893184.0\n",
      "  date: 2006-01-01\n",
      "  time: 0236\n",
      "  street1: WOODBINE AVE\n",
      "  street2: O CONNOR DR\n",
      "  offset: nan\n",
      "  road_class: Major Arterial\n",
      "  district: Toronto and East York\n",
      "  accloc: Intersection Related\n",
      "  ... (40 more columns hidden)\n",
      "\n",
      "Row 2:\n",
      "  _id: 2\n",
      "  accnum: 893184.0\n",
      "  date: 2006-01-01\n",
      "  time: 0236\n",
      "  street1: WOODBINE AVE\n",
      "  street2: O CONNOR DR\n",
      "  offset: nan\n",
      "  road_class: Major Arterial\n",
      "  district: Toronto and East York\n",
      "  accloc: Intersection Related\n",
      "  ... (40 more columns hidden)\n",
      "\n",
      "Row 3:\n",
      "  _id: 3\n",
      "  accnum: 893184.0\n",
      "  date: 2006-01-01\n",
      "  time: 0236\n",
      "  street1: WOODBINE AVE\n",
      "  street2: O CONNOR DR\n",
      "  offset: nan\n",
      "  road_class: Major Arterial\n",
      "  district: Toronto and East York\n",
      "  accloc: Intersection Related\n",
      "  ... (40 more columns hidden)\n",
      "\n",
      "Row 4:\n",
      "  _id: 4\n",
      "  accnum: 893184.0\n",
      "  date: 2006-01-01\n",
      "  time: 0236\n",
      "  street1: WOODBINE AVE\n",
      "  street2: O CONNOR DR\n",
      "  offset: nan\n",
      "  road_class: Major Arterial\n",
      "  district: Toronto and East York\n",
      "  accloc: Intersection Related\n",
      "  ... (40 more columns hidden)\n",
      "\n",
      "Row 5:\n",
      "  _id: 5\n",
      "  accnum: 893184.0\n",
      "  date: 2006-01-01\n",
      "  time: 0236\n",
      "  street1: WOODBINE AVE\n",
      "  street2: O CONNOR DR\n",
      "  offset: nan\n",
      "  road_class: Major Arterial\n",
      "  district: Toronto and East York\n",
      "  accloc: Intersection Related\n",
      "  ... (40 more columns hidden)\n",
      "\n",
      "Row 6:\n",
      "  _id: 6\n",
      "  accnum: 893184.0\n",
      "  date: 2006-01-01\n",
      "  time: 0236\n",
      "  street1: WOODBINE AVE\n",
      "  street2: O CONNOR DR\n",
      "  offset: nan\n",
      "  road_class: Major Arterial\n",
      "  district: Toronto and East York\n",
      "  accloc: Intersection Related\n",
      "  ... (40 more columns hidden)\n",
      "\n",
      "Row 7:\n",
      "  _id: 7\n",
      "  accnum: 893184.0\n",
      "  date: 2006-01-01\n",
      "  time: 0236\n",
      "  street1: WOODBINE AVE\n",
      "  street2: O CONNOR DR\n",
      "  offset: nan\n",
      "  road_class: Major Arterial\n",
      "  district: Toronto and East York\n",
      "  accloc: Intersection Related\n",
      "  ... (40 more columns hidden)\n",
      "\n",
      "Row 8:\n",
      "  _id: 8\n",
      "  accnum: 893184.0\n",
      "  date: 2006-01-01\n",
      "  time: 0236\n",
      "  street1: WOODBINE AVE\n",
      "  street2: O CONNOR DR\n",
      "  offset: nan\n",
      "  road_class: Major Arterial\n",
      "  district: Toronto and East York\n",
      "  accloc: Intersection Related\n",
      "  ... (40 more columns hidden)\n",
      "\n",
      "Row 9:\n",
      "  _id: 9\n",
      "  accnum: 909646.0\n",
      "  date: 2006-01-01\n",
      "  time: 0315\n",
      "  street1: DANFORTH AVE\n",
      "  street2: WEST LYNN AVE\n",
      "  offset: nan\n",
      "  road_class: Major Arterial\n",
      "  district: Toronto and East York\n",
      "  accloc: Intersection Related\n",
      "  ... (40 more columns hidden)\n",
      "\n",
      "Row 10:\n",
      "  _id: 10\n",
      "  accnum: 909646.0\n",
      "  date: 2006-01-01\n",
      "  time: 0315\n",
      "  street1: DANFORTH AVE\n",
      "  street2: WEST LYNN AVE\n",
      "  offset: nan\n",
      "  road_class: Major Arterial\n",
      "  district: Toronto and East York\n",
      "  accloc: Intersection Related\n",
      "  ... (40 more columns hidden)\n",
      "\n",
      "\n",
      "TMC Dataset:\n",
      "--------------------------------------------------------------------------------\n",
      "Row 1:\n",
      "  _id: 1\n",
      "  count_id: 25141\n",
      "  count_date: 2010-01-14\n",
      "  location_name: Lobb Ave / Shaw St\n",
      "  longitude: -79.4171307967992\n",
      "  latitude: 43.6469289677053\n",
      "  centreline_type: 2\n",
      "  centreline_id: 13467329\n",
      "  px: 1970.0\n",
      "  start_time: 2010-01-14T08:30:00\n",
      "  ... (45 more columns hidden)\n",
      "\n",
      "Row 2:\n",
      "  _id: 2\n",
      "  count_id: 25141\n",
      "  count_date: 2010-01-14\n",
      "  location_name: Lobb Ave / Shaw St\n",
      "  longitude: -79.4171307967992\n",
      "  latitude: 43.6469289677053\n",
      "  centreline_type: 2\n",
      "  centreline_id: 13467329\n",
      "  px: 1970.0\n",
      "  start_time: 2010-01-14T09:00:00\n",
      "  ... (45 more columns hidden)\n",
      "\n",
      "Row 3:\n",
      "  _id: 3\n",
      "  count_id: 25099\n",
      "  count_date: 2010-01-11\n",
      "  location_name: Richmond St W / Brant St\n",
      "  longitude: -79.3986568806368\n",
      "  latitude: 43.6474744990098\n",
      "  centreline_type: 2\n",
      "  centreline_id: 13467191\n",
      "  px: 2023.0\n",
      "  start_time: 2010-01-11T13:15:00\n",
      "  ... (45 more columns hidden)\n",
      "\n",
      "Row 4:\n",
      "  _id: 4\n",
      "  count_id: 25099\n",
      "  count_date: 2010-01-11\n",
      "  location_name: Richmond St W / Brant St\n",
      "  longitude: -79.3986568806368\n",
      "  latitude: 43.6474744990098\n",
      "  centreline_type: 2\n",
      "  centreline_id: 13467191\n",
      "  px: 2023.0\n",
      "  start_time: 2010-01-11T13:30:00\n",
      "  ... (45 more columns hidden)\n",
      "\n",
      "Row 5:\n",
      "  _id: 5\n",
      "  count_id: 25099\n",
      "  count_date: 2010-01-11\n",
      "  location_name: Richmond St W / Brant St\n",
      "  longitude: -79.3986568806368\n",
      "  latitude: 43.6474744990098\n",
      "  centreline_type: 2\n",
      "  centreline_id: 13467191\n",
      "  px: 2023.0\n",
      "  start_time: 2010-01-11T13:45:00\n",
      "  ... (45 more columns hidden)\n",
      "\n",
      "Row 6:\n",
      "  _id: 6\n",
      "  count_id: 25099\n",
      "  count_date: 2010-01-11\n",
      "  location_name: Richmond St W / Brant St\n",
      "  longitude: -79.3986568806368\n",
      "  latitude: 43.6474744990098\n",
      "  centreline_type: 2\n",
      "  centreline_id: 13467191\n",
      "  px: 2023.0\n",
      "  start_time: 2010-01-11T14:00:00\n",
      "  ... (45 more columns hidden)\n",
      "\n",
      "Row 7:\n",
      "  _id: 7\n",
      "  count_id: 25099\n",
      "  count_date: 2010-01-11\n",
      "  location_name: Richmond St W / Brant St\n",
      "  longitude: -79.3986568806368\n",
      "  latitude: 43.6474744990098\n",
      "  centreline_type: 2\n",
      "  centreline_id: 13467191\n",
      "  px: 2023.0\n",
      "  start_time: 2010-01-11T14:15:00\n",
      "  ... (45 more columns hidden)\n",
      "\n",
      "Row 8:\n",
      "  _id: 8\n",
      "  count_id: 25099\n",
      "  count_date: 2010-01-11\n",
      "  location_name: Richmond St W / Brant St\n",
      "  longitude: -79.3986568806368\n",
      "  latitude: 43.6474744990098\n",
      "  centreline_type: 2\n",
      "  centreline_id: 13467191\n",
      "  px: 2023.0\n",
      "  start_time: 2010-01-11T14:30:00\n",
      "  ... (45 more columns hidden)\n",
      "\n",
      "Row 9:\n",
      "  _id: 9\n",
      "  count_id: 25099\n",
      "  count_date: 2010-01-11\n",
      "  location_name: Richmond St W / Brant St\n",
      "  longitude: -79.3986568806368\n",
      "  latitude: 43.6474744990098\n",
      "  centreline_type: 2\n",
      "  centreline_id: 13467191\n",
      "  px: 2023.0\n",
      "  start_time: 2010-01-11T14:45:00\n",
      "  ... (45 more columns hidden)\n",
      "\n",
      "Row 10:\n",
      "  _id: 10\n",
      "  count_id: 25099\n",
      "  count_date: 2010-01-11\n",
      "  location_name: Richmond St W / Brant St\n",
      "  longitude: -79.3986568806368\n",
      "  latitude: 43.6474744990098\n",
      "  centreline_type: 2\n",
      "  centreline_id: 13467191\n",
      "  px: 2023.0\n",
      "  start_time: 2010-01-11T16:00:00\n",
      "  ... (45 more columns hidden)\n",
      "\n",
      "\n",
      "Police Collisions Dataset:\n",
      "--------------------------------------------------------------------------------\n",
      "Row 1:\n",
      "  x: 0.0\n",
      "  y: 0.0\n",
      "  objectid: 1\n",
      "  eventuniqueid: GO-20141001\n",
      "  occurrencedate: 2014/02/07 05:00:00+00\n",
      "  month: February\n",
      "  day_of_week: Friday\n",
      "  year: 2014\n",
      "  hour: 16\n",
      "  division: NSA\n",
      "  ... (9 more columns hidden)\n",
      "\n",
      "Row 2:\n",
      "  x: 0.0\n",
      "  y: 0.0\n",
      "  objectid: 2\n",
      "  eventuniqueid: GO-20141225593\n",
      "  occurrencedate: 2014/01/02 05:00:00+00\n",
      "  month: January\n",
      "  day_of_week: Thursday\n",
      "  year: 2014\n",
      "  hour: 3\n",
      "  division: NSA\n",
      "  ... (9 more columns hidden)\n",
      "\n",
      "Row 3:\n",
      "  x: 0.0\n",
      "  y: 0.0\n",
      "  objectid: 3\n",
      "  eventuniqueid: GO-20141260499\n",
      "  occurrencedate: 2014/01/01 05:00:00+00\n",
      "  month: January\n",
      "  day_of_week: Wednesday\n",
      "  year: 2014\n",
      "  hour: 2\n",
      "  division: NSA\n",
      "  ... (9 more columns hidden)\n",
      "\n",
      "Row 4:\n",
      "  x: 0.0\n",
      "  y: 0.0\n",
      "  objectid: 4\n",
      "  eventuniqueid: GO-20141260663\n",
      "  occurrencedate: 2014/01/01 05:00:00+00\n",
      "  month: January\n",
      "  day_of_week: Wednesday\n",
      "  year: 2014\n",
      "  hour: 3\n",
      "  division: NSA\n",
      "  ... (9 more columns hidden)\n",
      "\n",
      "Row 5:\n",
      "  x: 0.0\n",
      "  y: 0.0\n",
      "  objectid: 5\n",
      "  eventuniqueid: GO-20141261162\n",
      "  occurrencedate: 2014/01/01 05:00:00+00\n",
      "  month: January\n",
      "  day_of_week: Wednesday\n",
      "  year: 2014\n",
      "  hour: 5\n",
      "  division: NSA\n",
      "  ... (9 more columns hidden)\n",
      "\n",
      "Row 6:\n",
      "  x: 0.0\n",
      "  y: 0.0\n",
      "  objectid: 6\n",
      "  eventuniqueid: GO-20141261251\n",
      "  occurrencedate: 2014/01/01 05:00:00+00\n",
      "  month: January\n",
      "  day_of_week: Wednesday\n",
      "  year: 2014\n",
      "  hour: 5\n",
      "  division: NSA\n",
      "  ... (9 more columns hidden)\n",
      "\n",
      "Row 7:\n",
      "  x: 0.0\n",
      "  y: 0.0\n",
      "  objectid: 7\n",
      "  eventuniqueid: GO-20141261510\n",
      "  occurrencedate: 2014/01/01 05:00:00+00\n",
      "  month: January\n",
      "  day_of_week: Wednesday\n",
      "  year: 2014\n",
      "  hour: 8\n",
      "  division: NSA\n",
      "  ... (9 more columns hidden)\n",
      "\n",
      "Row 8:\n",
      "  x: 0.0\n",
      "  y: 0.0\n",
      "  objectid: 8\n",
      "  eventuniqueid: GO-20141261523\n",
      "  occurrencedate: 2014/01/01 05:00:00+00\n",
      "  month: January\n",
      "  day_of_week: Wednesday\n",
      "  year: 2014\n",
      "  hour: 8\n",
      "  division: NSA\n",
      "  ... (9 more columns hidden)\n",
      "\n",
      "Row 9:\n",
      "  x: 0.0\n",
      "  y: 0.0\n",
      "  objectid: 9\n",
      "  eventuniqueid: GO-20141261626\n",
      "  occurrencedate: 2014/01/01 05:00:00+00\n",
      "  month: January\n",
      "  day_of_week: Wednesday\n",
      "  year: 2014\n",
      "  hour: 9\n",
      "  division: NSA\n",
      "  ... (9 more columns hidden)\n",
      "\n",
      "Row 10:\n",
      "  x: 0.0\n",
      "  y: 0.0\n",
      "  objectid: 10\n",
      "  eventuniqueid: GO-20141261706\n",
      "  occurrencedate: 2014/01/01 05:00:00+00\n",
      "  month: January\n",
      "  day_of_week: Wednesday\n",
      "  year: 2014\n",
      "  hour: 9\n",
      "  division: NSA\n",
      "  ... (9 more columns hidden)\n",
      "\n",
      "\n",
      "Env Canada Weather Dataset:\n",
      "--------------------------------------------------------------------------------\n",
      "Row 1:\n",
      "  x: -79.4\n",
      "  y: 43.66666666666666\n",
      "  local_date: 2025-03-12 07:00:00\n",
      "  station_pressure: 100.47\n",
      "  temp_flag: nan\n",
      "  windchill: nan\n",
      "  local_hour: 7\n",
      "  relative_humidity: 54.0\n",
      "  wind_direction_flag: nan\n",
      "  wind_direction: nan\n",
      "  ... (27 more columns hidden)\n",
      "\n",
      "Row 2:\n",
      "  x: -79.4\n",
      "  y: 43.66666666666666\n",
      "  local_date: 2025-03-12 06:00:00\n",
      "  station_pressure: 100.39\n",
      "  temp_flag: nan\n",
      "  windchill: nan\n",
      "  local_hour: 6\n",
      "  relative_humidity: 53.0\n",
      "  wind_direction_flag: nan\n",
      "  wind_direction: nan\n",
      "  ... (27 more columns hidden)\n",
      "\n",
      "Row 3:\n",
      "  x: -79.4\n",
      "  y: 43.66666666666666\n",
      "  local_date: 2025-03-12 05:00:00\n",
      "  station_pressure: 100.34\n",
      "  temp_flag: nan\n",
      "  windchill: nan\n",
      "  local_hour: 5\n",
      "  relative_humidity: 46.0\n",
      "  wind_direction_flag: nan\n",
      "  wind_direction: nan\n",
      "  ... (27 more columns hidden)\n",
      "\n",
      "Row 4:\n",
      "  x: -79.4\n",
      "  y: 43.66666666666666\n",
      "  local_date: 2025-03-12 04:00:00\n",
      "  station_pressure: 100.29\n",
      "  temp_flag: nan\n",
      "  windchill: nan\n",
      "  local_hour: 4\n",
      "  relative_humidity: 47.0\n",
      "  wind_direction_flag: nan\n",
      "  wind_direction: nan\n",
      "  ... (27 more columns hidden)\n",
      "\n",
      "Row 5:\n",
      "  x: -79.4\n",
      "  y: 43.66666666666666\n",
      "  local_date: 2025-03-12 03:00:00\n",
      "  station_pressure: 100.3\n",
      "  temp_flag: nan\n",
      "  windchill: nan\n",
      "  local_hour: 3\n",
      "  relative_humidity: 48.0\n",
      "  wind_direction_flag: nan\n",
      "  wind_direction: nan\n",
      "  ... (27 more columns hidden)\n",
      "\n",
      "Row 6:\n",
      "  x: -79.4\n",
      "  y: 43.66666666666666\n",
      "  local_date: 2025-03-12 02:00:00\n",
      "  station_pressure: 100.34\n",
      "  temp_flag: nan\n",
      "  windchill: nan\n",
      "  local_hour: 2\n",
      "  relative_humidity: 48.0\n",
      "  wind_direction_flag: nan\n",
      "  wind_direction: nan\n",
      "  ... (27 more columns hidden)\n",
      "\n",
      "Row 7:\n",
      "  x: -79.4\n",
      "  y: 43.66666666666666\n",
      "  local_date: 2025-03-12 01:00:00\n",
      "  station_pressure: 100.34\n",
      "  temp_flag: nan\n",
      "  windchill: nan\n",
      "  local_hour: 1\n",
      "  relative_humidity: 50.0\n",
      "  wind_direction_flag: nan\n",
      "  wind_direction: nan\n",
      "  ... (27 more columns hidden)\n",
      "\n",
      "Row 8:\n",
      "  x: -79.4\n",
      "  y: 43.66666666666666\n",
      "  local_date: 2025-03-12 00:00:00\n",
      "  station_pressure: 100.3\n",
      "  temp_flag: nan\n",
      "  windchill: nan\n",
      "  local_hour: 0\n",
      "  relative_humidity: 51.0\n",
      "  wind_direction_flag: nan\n",
      "  wind_direction: nan\n",
      "  ... (27 more columns hidden)\n",
      "\n",
      "Row 9:\n",
      "  x: -79.4\n",
      "  y: 43.66666666666666\n",
      "  local_date: 2025-03-11 23:00:00\n",
      "  station_pressure: 100.28\n",
      "  temp_flag: nan\n",
      "  windchill: nan\n",
      "  local_hour: 23\n",
      "  relative_humidity: 49.0\n",
      "  wind_direction_flag: nan\n",
      "  wind_direction: nan\n",
      "  ... (27 more columns hidden)\n",
      "\n",
      "Row 10:\n",
      "  x: -79.4\n",
      "  y: 43.66666666666666\n",
      "  local_date: 2025-03-11 22:00:00\n",
      "  station_pressure: 100.21\n",
      "  temp_flag: nan\n",
      "  windchill: nan\n",
      "  local_hour: 22\n",
      "  relative_humidity: 53.0\n",
      "  wind_direction_flag: nan\n",
      "  wind_direction: nan\n",
      "  ... (27 more columns hidden)\n",
      "\n",
      "\n",
      "ERA5 Dataset:\n",
      "--------------------------------------------------------------------------------\n",
      "Row 1:\n",
      "  system:index: 0_20150101T00\n",
      "  dewpoint_temperature_2m: 256.3797302246094\n",
      "  location: Downtown\n",
      "  surface_pressure: 100259.50390625\n",
      "  temperature_2m: 267.4694366455078\n",
      "  timestamp: 2015-01-01 00:00\n",
      "  total_precipitation: 0.0002673029898687673\n",
      "  u_component_of_wind_10m: 7.538604736328125\n",
      "  v_component_of_wind_10m: 3.411712646484375\n",
      "  .geo: {\"type\":\"Point\",\"coordinates\":[-79.3832,43.6532]}\n",
      "\n",
      "Row 2:\n",
      "  system:index: 0_20150101T01\n",
      "  dewpoint_temperature_2m: 256.66746520996094\n",
      "  location: Downtown\n",
      "  surface_pressure: 100153.52734375\n",
      "  temperature_2m: 267.3900604248047\n",
      "  timestamp: 2015-01-01 01:00\n",
      "  total_precipitation: 6.509944796562195e-06\n",
      "  u_component_of_wind_10m: 7.506500244140625\n",
      "  v_component_of_wind_10m: 3.796295166015625\n",
      "  .geo: {\"type\":\"Point\",\"coordinates\":[-79.3832,43.6532]}\n",
      "\n",
      "Row 3:\n",
      "  system:index: 0_20150101T02\n",
      "  dewpoint_temperature_2m: 256.78440856933594\n",
      "  location: Downtown\n",
      "  surface_pressure: 100093.9375\n",
      "  temperature_2m: 267.2943420410156\n",
      "  timestamp: 2015-01-01 02:00\n",
      "  total_precipitation: 1.4923512935638428e-05\n",
      "  u_component_of_wind_10m: 7.861251831054687\n",
      "  v_component_of_wind_10m: 3.563995361328125\n",
      "  .geo: {\"type\":\"Point\",\"coordinates\":[-79.3832,43.6532]}\n",
      "\n",
      "Row 4:\n",
      "  system:index: 0_20150101T03\n",
      "  dewpoint_temperature_2m: 256.67076110839844\n",
      "  location: Downtown\n",
      "  surface_pressure: 100044.53125\n",
      "  temperature_2m: 267.1153869628906\n",
      "  timestamp: 2015-01-01 03:00\n",
      "  total_precipitation: 2.148747444152832e-05\n",
      "  u_component_of_wind_10m: 8.11920166015625\n",
      "  v_component_of_wind_10m: 3.0960845947265625\n",
      "  .geo: {\"type\":\"Point\",\"coordinates\":[-79.3832,43.6532]}\n",
      "\n",
      "Row 5:\n",
      "  system:index: 0_20150101T04\n",
      "  dewpoint_temperature_2m: 257.20143127441406\n",
      "  location: Downtown\n",
      "  surface_pressure: 100012.3984375\n",
      "  temperature_2m: 266.8501892089844\n",
      "  timestamp: 2015-01-01 04:00\n",
      "  total_precipitation: 2.3253262042999268e-05\n",
      "  u_component_of_wind_10m: 7.92523193359375\n",
      "  v_component_of_wind_10m: 2.7824249267578125\n",
      "  .geo: {\"type\":\"Point\",\"coordinates\":[-79.3832,43.6532]}\n",
      "\n",
      "Row 6:\n",
      "  system:index: 0_20150101T05\n",
      "  dewpoint_temperature_2m: 257.5321350097656\n",
      "  location: Downtown\n",
      "  surface_pressure: 99980.4921875\n",
      "  temperature_2m: 266.5321807861328\n",
      "  timestamp: 2015-01-01 05:00\n",
      "  total_precipitation: 2.4840235710144043e-05\n",
      "  u_component_of_wind_10m: 7.719406127929687\n",
      "  v_component_of_wind_10m: 2.7760162353515625\n",
      "  .geo: {\"type\":\"Point\",\"coordinates\":[-79.3832,43.6532]}\n",
      "\n",
      "Row 7:\n",
      "  system:index: 0_20150101T06\n",
      "  dewpoint_temperature_2m: 257.6045684814453\n",
      "  location: Downtown\n",
      "  surface_pressure: 99925.15234375\n",
      "  temperature_2m: 266.2963409423828\n",
      "  timestamp: 2015-01-01 06:00\n",
      "  total_precipitation: 2.6404857635498047e-05\n",
      "  u_component_of_wind_10m: 7.27752685546875\n",
      "  v_component_of_wind_10m: 3.17889404296875\n",
      "  .geo: {\"type\":\"Point\",\"coordinates\":[-79.3832,43.6532]}\n",
      "\n",
      "Row 8:\n",
      "  system:index: 0_20150101T07\n",
      "  dewpoint_temperature_2m: 257.7323455810547\n",
      "  location: Downtown\n",
      "  surface_pressure: 99844.08203125\n",
      "  temperature_2m: 266.4271240234375\n",
      "  timestamp: 2015-01-01 07:00\n",
      "  total_precipitation: 2.7514994144439697e-05\n",
      "  u_component_of_wind_10m: 7.909805297851562\n",
      "  v_component_of_wind_10m: 3.658966064453125\n",
      "  .geo: {\"type\":\"Point\",\"coordinates\":[-79.3832,43.6532]}\n",
      "\n",
      "Row 9:\n",
      "  system:index: 0_20150101T08\n",
      "  dewpoint_temperature_2m: 258.5003356933594\n",
      "  location: Downtown\n",
      "  surface_pressure: 99820.16796875\n",
      "  temperature_2m: 266.5484313964844\n",
      "  timestamp: 2015-01-01 08:00\n",
      "  total_precipitation: 2.9258430004119876e-05\n",
      "  u_component_of_wind_10m: 7.749969482421875\n",
      "  v_component_of_wind_10m: 4.0165557861328125\n",
      "  .geo: {\"type\":\"Point\",\"coordinates\":[-79.3832,43.6532]}\n",
      "\n",
      "Row 10:\n",
      "  system:index: 0_20150101T09\n",
      "  dewpoint_temperature_2m: 259.22731018066406\n",
      "  location: Downtown\n",
      "  surface_pressure: 99771.52734375\n",
      "  temperature_2m: 266.6808776855469\n",
      "  timestamp: 2015-01-01 09:00\n",
      "  total_precipitation: 3.1754374504089355e-05\n",
      "  u_component_of_wind_10m: 7.404983520507812\n",
      "  v_component_of_wind_10m: 4.2101593017578125\n",
      "  .geo: {\"type\":\"Point\",\"coordinates\":[-79.3832,43.6532]}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def print_dataset_examples(df, name, max_rows=10, max_cols=10):\n",
    "    \"\"\"\n",
    "    Prints out example rows (not tabular) with all columns shown per row.\n",
    "    This is designed to be copy-paste friendly for language model prompts.\n",
    "    \"\"\"\n",
    "    print(f\"\\n{name}:\\n\" + \"-\" * 80)\n",
    "    rows = df.dropna(how=\"all\").head(max_rows)\n",
    "    for i, (_, row) in enumerate(rows.iterrows(), 1):\n",
    "        print(f\"Row {i}:\")\n",
    "        for j, col in enumerate(row.index):\n",
    "            if j >= max_cols:\n",
    "                print(f\"  ... ({len(row.index) - max_cols} more columns hidden)\")\n",
    "                break\n",
    "            print(f\"  {col}: {row[col]}\")\n",
    "        print(\"\")\n",
    "\n",
    "# Call the function on all 5 datasets\n",
    "print_dataset_examples(df_ksi, \"KSI Dataset\", max_rows=10)\n",
    "print_dataset_examples(df_tmc, \"TMC Dataset\", max_rows=10)\n",
    "print_dataset_examples(df_collisions, \"Police Collisions Dataset\", max_rows=10)\n",
    "print_dataset_examples(df_env, \"Env Canada Weather Dataset\", max_rows=10)\n",
    "print_dataset_examples(df_era5, \"ERA5 Dataset\", max_rows=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'date'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mE:\\manav\\Documents\\Masters\\ES8922\\Weather_Based_Traffic_Prediction\\venv\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3805\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3804\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3805\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3806\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mindex.pyx:167\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mindex.pyx:196\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7081\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7089\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mKeyError\u001b[39m: 'date'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[26]\u001b[39m\u001b[32m, line 60\u001b[39m\n\u001b[32m     57\u001b[39m     df_era5[\u001b[33m\"\u001b[39m\u001b[33mlat\u001b[39m\u001b[33m\"\u001b[39m] = np.nan\n\u001b[32m     59\u001b[39m \u001b[38;5;66;03m# STEP 6: Normalize Temporal Features\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m60\u001b[39m df_ksi[\u001b[33m\"\u001b[39m\u001b[33mdate\u001b[39m\u001b[33m\"\u001b[39m] = pd.to_datetime(\u001b[43mdf_ksi\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdate\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m, errors=\u001b[33m\"\u001b[39m\u001b[33mcoerce\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     61\u001b[39m df_ksi[\u001b[33m\"\u001b[39m\u001b[33mtime\u001b[39m\u001b[33m\"\u001b[39m] = df_ksi[\u001b[33m\"\u001b[39m\u001b[33mtime\u001b[39m\u001b[33m\"\u001b[39m].astype(\u001b[38;5;28mstr\u001b[39m).str.zfill(\u001b[32m4\u001b[39m)\n\u001b[32m     62\u001b[39m df_ksi[\u001b[33m\"\u001b[39m\u001b[33mdatetime\u001b[39m\u001b[33m\"\u001b[39m] = pd.to_datetime(df_ksi[\u001b[33m\"\u001b[39m\u001b[33mdate\u001b[39m\u001b[33m\"\u001b[39m].dt.strftime(\u001b[33m\"\u001b[39m\u001b[33m%\u001b[39m\u001b[33mY-\u001b[39m\u001b[33m%\u001b[39m\u001b[33mm-\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[33m\"\u001b[39m) + \u001b[33m\"\u001b[39m\u001b[33m \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     63\u001b[39m                                     + df_ksi[\u001b[33m\"\u001b[39m\u001b[33mtime\u001b[39m\u001b[33m\"\u001b[39m].str[:\u001b[32m2\u001b[39m] + \u001b[33m\"\u001b[39m\u001b[33m:\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     64\u001b[39m                                     + df_ksi[\u001b[33m\"\u001b[39m\u001b[33mtime\u001b[39m\u001b[33m\"\u001b[39m].str[\u001b[32m2\u001b[39m:], errors=\u001b[33m\"\u001b[39m\u001b[33mcoerce\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mE:\\manav\\Documents\\Masters\\ES8922\\Weather_Based_Traffic_Prediction\\venv\\Lib\\site-packages\\pandas\\core\\frame.py:4102\u001b[39m, in \u001b[36mDataFrame.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   4100\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.columns.nlevels > \u001b[32m1\u001b[39m:\n\u001b[32m   4101\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._getitem_multilevel(key)\n\u001b[32m-> \u001b[39m\u001b[32m4102\u001b[39m indexer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4103\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[32m   4104\u001b[39m     indexer = [indexer]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mE:\\manav\\Documents\\Masters\\ES8922\\Weather_Based_Traffic_Prediction\\venv\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3807\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   3808\u001b[39m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc.Iterable)\n\u001b[32m   3809\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[32m   3810\u001b[39m     ):\n\u001b[32m   3811\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[32m-> \u001b[39m\u001b[32m3812\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n\u001b[32m   3813\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[32m   3814\u001b[39m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[32m   3815\u001b[39m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[32m   3816\u001b[39m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[32m   3817\u001b[39m     \u001b[38;5;28mself\u001b[39m._check_indexing_error(key)\n",
      "\u001b[31mKeyError\u001b[39m: 'date'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import math\n",
    "\n",
    "def parse_geojson(geo_str):\n",
    "    if pd.isna(geo_str):\n",
    "        return (None, None)\n",
    "    try:\n",
    "        g = json.loads(str(geo_str))\n",
    "        coords = g.get(\"coordinates\", [None, None])\n",
    "        if coords and len(coords) == 2:\n",
    "            return (coords[0], coords[1])\n",
    "        else:\n",
    "            return (None, None)\n",
    "    except:\n",
    "        return (None, None)\n",
    "\n",
    "def haversine_distance(lat1, lon1, lat2, lon2):\n",
    "    R = 6371.0\n",
    "    d_lat = np.radians(lat2 - lat1)\n",
    "    d_lon = np.radians(lon2 - lon1)\n",
    "    a = (np.sin(d_lat/2) ** 2\n",
    "         + np.cos(np.radians(lat1)) * np.cos(np.radians(lat2))\n",
    "         * np.sin(d_lon/2) ** 2)\n",
    "    c = 2 * np.arcsin(np.sqrt(a))\n",
    "    return R * c\n",
    "\n",
    "# # Read your datasets (adjust filenames/paths as needed)\n",
    "# df_ksi = pd.read_csv(\"KSI.csv\")\n",
    "# df_tmc = pd.read_csv(\"TMC.csv\")\n",
    "# df_collisions = pd.read_csv(\"Police_Collisions.csv\")\n",
    "# df_env = pd.read_csv(\"Env_Canada.csv\")\n",
    "# df_era5 = pd.read_csv(\"ERA5.csv\")\n",
    "\n",
    "# STEP 5: Standardize Coordinates\n",
    "if \"geometry\" in df_ksi.columns:\n",
    "    df_ksi[\"lon\"], df_ksi[\"lat\"] = zip(*df_ksi[\"geometry\"].apply(parse_geojson))\n",
    "if \"lon\" not in df_ksi.columns:\n",
    "    df_ksi[\"lon\"] = np.nan\n",
    "if \"lat\" not in df_ksi.columns:\n",
    "    df_ksi[\"lat\"] = np.nan\n",
    "\n",
    "df_tmc.rename(columns={\"longitude\": \"lon\", \"latitude\": \"lat\"}, inplace=True)\n",
    "\n",
    "if \"x\" in df_collisions.columns and \"y\" in df_collisions.columns:\n",
    "    df_collisions.rename(columns={\"x\": \"lon\", \"y\": \"lat\"}, inplace=True)\n",
    "\n",
    "if \"x\" in df_env.columns and \"y\" in df_env.columns:\n",
    "    df_env.rename(columns={\"x\": \"lon\", \"y\": \"lat\"}, inplace=True)\n",
    "\n",
    "if \".geo\" in df_era5.columns:\n",
    "    df_era5[\"lon\"], df_era5[\"lat\"] = zip(*df_era5[\".geo\"].apply(parse_geojson))\n",
    "if \"lon\" not in df_era5.columns:\n",
    "    df_era5[\"lon\"] = np.nan\n",
    "if \"lat\" not in df_era5.columns:\n",
    "    df_era5[\"lat\"] = np.nan\n",
    "\n",
    "# STEP 6: Normalize Temporal Features\n",
    "df_ksi[\"date\"] = pd.to_datetime(df_ksi[\"date\"], errors=\"coerce\")\n",
    "df_ksi[\"time\"] = df_ksi[\"time\"].astype(str).str.zfill(4)\n",
    "df_ksi[\"datetime\"] = pd.to_datetime(df_ksi[\"date\"].dt.strftime(\"%Y-%m-%d\") + \" \"\n",
    "                                    + df_ksi[\"time\"].str[:2] + \":\"\n",
    "                                    + df_ksi[\"time\"].str[2:], errors=\"coerce\")\n",
    "df_ksi[\"datetime\"] = df_ksi[\"datetime\"].dt.round(\"H\")\n",
    "\n",
    "df_tmc[\"count_date\"] = pd.to_datetime(df_tmc[\"count_date\"], errors=\"coerce\")\n",
    "df_tmc[\"start_time\"] = pd.to_datetime(df_tmc[\"start_time\"], errors=\"coerce\")\n",
    "df_tmc[\"timestamp\"] = pd.to_datetime(df_tmc[\"count_date\"].dt.strftime(\"%Y-%m-%d\") + \" \"\n",
    "                                     + df_tmc[\"start_time\"].dt.strftime(\"%H:%M\"), errors=\"coerce\")\n",
    "df_tmc[\"timestamp\"] = df_tmc[\"timestamp\"].dt.round(\"H\")\n",
    "\n",
    "df_collisions[\"occurrencedate\"] = pd.to_datetime(df_collisions[\"occurrencedate\"], errors=\"coerce\")\n",
    "df_collisions[\"occurrencedate\"] = df_collisions[\"occurrencedate\"].dt.round(\"H\")\n",
    "df_collisions.rename(columns={\"occurrencedate\": \"timestamp\"}, inplace=True)\n",
    "\n",
    "df_env[\"local_date\"] = pd.to_datetime(df_env[\"local_date\"], errors=\"coerce\")\n",
    "df_env[\"timestamp\"] = pd.to_datetime(df_env[\"local_date\"].dt.strftime(\"%Y-%m-%d\") + \" \"\n",
    "                                     + df_env[\"local_hour\"].astype(str) + \":00\", errors=\"coerce\")\n",
    "df_env[\"timestamp\"] = df_env[\"timestamp\"].dt.round(\"H\")\n",
    "\n",
    "df_era5[\"timestamp\"] = pd.to_datetime(df_era5[\"timestamp\"], errors=\"coerce\")\n",
    "df_era5[\"timestamp\"] = df_era5[\"timestamp\"].dt.round(\"H\")\n",
    "\n",
    "# STEP 7: Compute Weather Features from ERA5\n",
    "df_era5[\"temp_c\"] = df_era5[\"temperature_2m\"] - 273.15\n",
    "df_era5[\"wind_speed\"] = np.sqrt(df_era5[\"u_component_of_wind_10m\"]**2\n",
    "                                + df_era5[\"v_component_of_wind_10m\"]**2)\n",
    "\n",
    "# STEP 8: Summarize TMC Traffic Volume\n",
    "if \"total_traffic_volume\" not in df_tmc.columns:\n",
    "    df_tmc[\"total_traffic_volume\"] = np.random.randint(0, 200, size=len(df_tmc))\n",
    "\n",
    "# STEP 9: Merge TMC and ERA5 by Nearest Time + Location (Within 2 km)\n",
    "common_timestamps = set(df_tmc[\"timestamp\"]).intersection(set(df_era5[\"timestamp\"]))\n",
    "era5_sub = df_era5[df_era5[\"timestamp\"].isin(common_timestamps)].copy()\n",
    "df_tmc = df_tmc.reset_index().rename(columns={\"index\": \"_original_tmc_idx\"})\n",
    "merged = pd.merge(df_tmc, era5_sub, on=\"timestamp\", how=\"inner\", suffixes=(\"_tmc\",\"_era5\"))\n",
    "merged[\"distance_km\"] = haversine_distance(merged[\"lat_tmc\"], merged[\"lon_tmc\"],\n",
    "                                           merged[\"lat_era5\"], merged[\"lon_era5\"])\n",
    "merged = merged[merged[\"distance_km\"] <= 2]\n",
    "merged.reset_index(drop=True, inplace=True)\n",
    "closest = merged.loc[merged.groupby(\"_original_tmc_idx\")[\"distance_km\"].idxmin()].copy()\n",
    "\n",
    "df_final = closest[[\n",
    "    \"timestamp\",\n",
    "    \"location_name\",\n",
    "    \"lat_tmc\",\n",
    "    \"lon_tmc\",\n",
    "    \"temp_c\",\n",
    "    \"wind_speed\",\n",
    "    \"total_traffic_volume\"\n",
    "]].copy()\n",
    "df_final.rename(columns={\"lat_tmc\": \"lat\", \"lon_tmc\": \"lon\"}, inplace=True)\n",
    "\n",
    "# STEP 10: Create Ground Truth Labels\n",
    "bins = [0, 50, 100, np.inf]\n",
    "labels = [\"Low\", \"Medium\", \"High\"]\n",
    "df_final[\"congestion_level\"] = pd.cut(df_final[\"total_traffic_volume\"], bins=bins, labels=labels)\n",
    "\n",
    "# STEP 11: Feature Engineering\n",
    "df_final[\"hour\"] = df_final[\"timestamp\"].dt.hour\n",
    "df_final[\"day_of_week\"] = df_final[\"timestamp\"].dt.day_name()\n",
    "df_final[\"month\"] = df_final[\"timestamp\"].dt.month\n",
    "\n",
    "def simple_weather_summary(temp_c):\n",
    "    if temp_c is None or pd.isna(temp_c):\n",
    "        return \"Unknown\"\n",
    "    if temp_c <= 0:\n",
    "        return f\"Snowy, {temp_c:.1f}C\"\n",
    "    elif temp_c >= 20:\n",
    "        return f\"Sunny, {temp_c:.1f}C\"\n",
    "    else:\n",
    "        return f\"Rainy, {temp_c:.1f}C\"\n",
    "\n",
    "df_final[\"weather_summary\"] = df_final[\"temp_c\"].apply(simple_weather_summary)\n",
    "\n",
    "# STEP 12: Final Cleanup\n",
    "df_final.sort_values(\"timestamp\", inplace=True)\n",
    "df_final.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# STEP 13: Save Final Dataset\n",
    "df_final.to_csv(\"final_congestion_dataset.csv\", index=False)\n",
    "\n",
    "print(df_final.head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame shape: (32606, 12)\n",
      "\n",
      "DataFrame Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 32606 entries, 0 to 32605\n",
      "Data columns (total 12 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   timestamp             32606 non-null  object \n",
      " 1   location_name         32606 non-null  object \n",
      " 2   lat                   32606 non-null  float64\n",
      " 3   lon                   32606 non-null  float64\n",
      " 4   temp_c                32606 non-null  float64\n",
      " 5   wind_speed            32606 non-null  float64\n",
      " 6   total_traffic_volume  32606 non-null  int64  \n",
      " 7   congestion_level      32434 non-null  object \n",
      " 8   hour                  32606 non-null  int64  \n",
      " 9   day_of_week           32606 non-null  object \n",
      " 10  month                 32606 non-null  int64  \n",
      " 11  weather_summary       32606 non-null  object \n",
      "dtypes: float64(4), int64(3), object(5)\n",
      "memory usage: 3.0+ MB\n",
      "\n",
      "Missing Values Per Column:\n",
      "timestamp                 0\n",
      "location_name             0\n",
      "lat                       0\n",
      "lon                       0\n",
      "temp_c                    0\n",
      "wind_speed                0\n",
      "total_traffic_volume      0\n",
      "congestion_level        172\n",
      "hour                      0\n",
      "day_of_week               0\n",
      "month                     0\n",
      "weather_summary           0\n",
      "dtype: int64\n",
      "\n",
      "Columns with Missing Values:\n",
      "congestion_level    172\n",
      "dtype: int64\n",
      "\n",
      "Percentage of Missing Values Per Column:\n",
      "congestion_level    0.52751\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV file\n",
    "df = pd.read_csv(\"final_congestion_dataset.csv\")\n",
    "\n",
    "# Print the overall shape of the DataFrame\n",
    "print(\"DataFrame shape:\", df.shape)\n",
    "\n",
    "# Print summary information about the DataFrame (column types, non-null counts, etc.)\n",
    "print(\"\\nDataFrame Info:\")\n",
    "df.info()\n",
    "\n",
    "# Calculate the number of missing values in each column\n",
    "missing_counts = df.isna().sum()\n",
    "print(\"\\nMissing Values Per Column:\")\n",
    "print(missing_counts)\n",
    "\n",
    "# Print only the columns that have missing values\n",
    "missing_columns = missing_counts[missing_counts > 0]\n",
    "print(\"\\nColumns with Missing Values:\")\n",
    "print(missing_columns)\n",
    "\n",
    "# Calculate and print the percentage of missing values for those columns\n",
    "missing_percentage = (missing_columns / len(df)) * 100\n",
    "print(\"\\nPercentage of Missing Values Per Column:\")\n",
    "print(missing_percentage)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing Values After Update:\n",
      "timestamp               0\n",
      "location_name           0\n",
      "lat                     0\n",
      "lon                     0\n",
      "temp_c                  0\n",
      "wind_speed              0\n",
      "total_traffic_volume    0\n",
      "congestion_level        0\n",
      "hour                    0\n",
      "day_of_week             0\n",
      "month                   0\n",
      "weather_summary         0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Drop rows where congestion_level is NaN\n",
    "df_final.dropna(subset=['congestion_level'], inplace=True)\n",
    "\n",
    "# Save the updated DataFrame back to the same CSV file\n",
    "df_final.to_csv(\"final_congestion_dataset.csv\", index=False)\n",
    "\n",
    "# Re-import the CSV file\n",
    "df_final_updated = pd.read_csv(\"final_congestion_dataset.csv\")\n",
    "\n",
    "# Check for any remaining NaN values\n",
    "print(\"Missing Values After Update:\")\n",
    "print(df_final_updated.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Traffic & Weather)",
   "language": "python",
   "name": "traffic-weather-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
